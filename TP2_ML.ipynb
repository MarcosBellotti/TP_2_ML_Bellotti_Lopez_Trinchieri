{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# un poco menos de warnings de tensorflow\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# de python, para especificar rutas de archivos y directorios\n",
    "from pathlib import Path\n",
    "\n",
    "# lib para trabajar con arrays\n",
    "import numpy as np\n",
    "\n",
    "# lib que usamos para mostrar las imágenes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# libs que usamos para construir y entrenar redes neuronales, y que además tiene utilidades para leer sets de \n",
    "# imágenes\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# libs que usamos para tareas generales de machine learning. En este caso, métricas\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# configuración para que las imágenes se vean dentro del notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuraciones iniciales de alguans constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIAS = 'buildings', 'forest', 'glacier', 'mountain', 'sea', 'street'\n",
    "# configurar de acuerdo a dónde bajaron los sets de imágenes\n",
    "TRAIN_DIR = Path('./imagenes/train')\n",
    "VALIDATION_DIR = Path('./imagenes/validation')\n",
    "SIZE = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_reader = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    rotation_range=10,\n",
    "    #width_shift_range=0.3,\n",
    "    #height_shift_range=0.3,\n",
    "    brightness_range=(0.5, 1.5),\n",
    "    #horizontal_flip=True,\n",
    "    #vertical_flip=True,\n",
    ")\n",
    "\n",
    "READ_PARAMS = dict(\n",
    "    class_mode=\"categorical\",  # tenemos N labels, queremos tuplas de 0s y 1s indicando cuál de los labels es\n",
    "    classes=CATEGORIAS,  # para usar el mismo orden en todos lados\n",
    "    target_size=(SIZE, SIZE),  # para que corra más rápido, vamos a achicar las imágenes\n",
    "    color_mode=\"rgb\",  # queremos trabajar con las imágenes a color\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtenemos los conjuntos de train y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = images_reader.flow_from_directory(TRAIN_DIR, **READ_PARAMS)\n",
    "validation = images_reader.flow_from_directory(VALIDATION_DIR, **READ_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para mostrar algunas imagenes del dataset\n",
    "def sample_images(dataset):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    images, labels = next(dataset)\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(CATEGORIAS[np.argmax(labels[i])])\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "sample_images(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empezamos a trabajar con las redes neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# el shape de los inputs es alto_imagen * ancho_imagen * cantidad_colores\n",
    "input_shape = (SIZE, SIZE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP simple\n",
    "model = Sequential([\n",
    "    Input(input_shape),\n",
    "    \n",
    "    Flatten(),\n",
    "\n",
    "    Dense(500, activation='tanh'),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Dense(len(CATEGORIAS), activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolucional\n",
    "model = Sequential([\n",
    "    Input(input_shape),\n",
    "\n",
    "    Convolution2D(filters=10, kernel_size=(4, 4), strides=1, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Convolution2D(filters=10, kernel_size=(4, 4), strides=1, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    MaxPooling2D(pool_size=(4, 4)),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(100, activation='tanh'),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Dense(len(CATEGORIAS), activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolucional usando convoluciones ya entrenadas de VGG16\n",
    "pretrained_model = VGG16(input_shape=input_shape, include_top=False)\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    pretrained_model,\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(100, activation='tanh'),\n",
    "    Dense(100, activation='tanh'),\n",
    "    \n",
    "    Dense(len(CATEGORIAS), activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_at_epochs = {}\n",
    "\n",
    "class OurCustomCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        model_weights_at_epochs[epoch] = self.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train,\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    validation_data=validation,\n",
    "    callbacks=[OurCustomCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos el accuracy de ambos conjuntos, tanto train como validation, durante todo el proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')\n",
    "plt.title('Accuracy over train epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elegimos la que consideremos como la mejor epoca y nos quedamos con ese conjunto de pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_EPOCH = 4\n",
    "model.set_weights(model_weights_at_epochs[BEST_EPOCH])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora analizamos el error de ambos conjuntos para sacar nuestras propias conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = (\n",
    "    ('train', images_reader.flow_from_directory(TRAIN_DIR, **READ_PARAMS, batch_size=-1)),\n",
    "    ('validation', images_reader.flow_from_directory(VALIDATION_DIR, **READ_PARAMS, batch_size=-1)),\n",
    ")\n",
    "\n",
    "for dataset_name, dataset in datasets:\n",
    "    print('#' * 25, dataset_name, '#' * 25)\n",
    "\n",
    "    batch_images, batch_labels = next(dataset)\n",
    "    \n",
    "    # super importante: usamos argmax para convertir cosas de este formato:\n",
    "    # [(0, 1, 0), (1, 0, 0), (1, 0, 0), (0, 0, 1)]\n",
    "    # a este formato (donde tenemos el índice de la clase que tiene número más alto):\n",
    "    # [1, 0, 0, 2]\n",
    "    predictions = np.argmax(model.predict(batch_images), axis=-1)\n",
    "    labels = np.argmax(batch_labels, axis=-1)\n",
    "    \n",
    "    print('Accuracy:', accuracy_score(labels, predictions))\n",
    "\n",
    "    # graficamos la confussion matrix\n",
    "    plt.figure(figsize=(3, 4))\n",
    "        \n",
    "    plt.xticks([0, 1, 2], CATEGORIAS, rotation=45)\n",
    "    plt.yticks([0, 1, 2], CATEGORIAS)\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.ylabel('True class')\n",
    "\n",
    "    plt.imshow(\n",
    "        confusion_matrix(labels, predictions), \n",
    "        cmap=plt.cm.Blues,\n",
    "        interpolation='nearest',\n",
    "    )\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora probaremos con nuestras propias imágenes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "def show_and_predict(image_path):\n",
    "    image_array = img_to_array(load_img(image_path, target_size=(SIZE, SIZE)))\n",
    "    inputs = np.array([image_array])  # armamos un \"dataset\" con solo esa imagen\n",
    "    predictions = model.predict(inputs)\n",
    "    display(Image(image_path, width=500))\n",
    "    print(\"Prediction:\", CATEGORIAS[np.argmax(predictions)])\n",
    "    print(\"Prediction detail:\", predictions)\n",
    "show_and_predict(\"./fisa_pelado.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
